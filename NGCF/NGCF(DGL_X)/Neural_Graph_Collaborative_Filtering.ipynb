{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKE5nzqY2SrP"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm \n",
        "import os \n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "import scipy.sparse  as sp \n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "import torch \n",
        "from torch import nn, optim \n",
        "from torch.utils.data import Dataset, DataLoader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXLeESD82SrR"
      },
      "outputs": [],
      "source": [
        "class args:\n",
        "    seed = 42\n",
        "    num_layers = 3\n",
        "    batch_size= 512\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SAVE_PATH = 'Parameters'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh6jK1_92SrS"
      },
      "outputs": [],
      "source": [
        "d_set = pd.read_csv('dataset/MovieLens1M/ratings.dat', sep='::', names=['user_id','business_id','stars','ts'], encoding='latin-1',header=None)\n",
        "d_set = d_set.drop(columns=['ts'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qekorfxd2SrS"
      },
      "outputs": [],
      "source": [
        "d_train, d_test = train_test_split(d_set, train_size=0.6, random_state=args.seed)\n",
        "d_valid, d_test = train_test_split(d_test, train_size=0.5, random_state=args.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL-lRSH-2SrS"
      },
      "outputs": [],
      "source": [
        "d_train = d_train.astype({'user_id':'category', 'business_id':'category'})\n",
        "d_valid = d_valid.astype({'user_id':'category', 'business_id':'category'})\n",
        "d_test = d_test.astype({'user_id':'category', 'business_id':'category'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4bkMkyU2SrS"
      },
      "outputs": [],
      "source": [
        "u_cat = d_train.user_id.cat.categories\n",
        "b_cat = d_train.business_id.cat.categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV0x8d3I2SrT"
      },
      "outputs": [],
      "source": [
        "d_valid.user_id = d_valid.user_id.cat.set_categories(u_cat)\n",
        "d_valid.business_id = d_valid.business_id.cat.set_categories(b_cat)\n",
        "\n",
        "d_test.user_id = d_test.user_id.cat.set_categories(u_cat)\n",
        "d_test.business_id = d_test.business_id.cat.set_categories(b_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU_w8ycZ2SrT"
      },
      "outputs": [],
      "source": [
        "d_train.user_id = d_train.user_id.cat.codes\n",
        "d_train.business_id = d_train.business_id.cat.codes \n",
        "\n",
        "d_valid.user_id = d_valid.user_id.cat.codes\n",
        "d_valid.business_id = d_valid.business_id.cat.codes \n",
        "\n",
        "d_test.user_id = d_test.user_id.cat.codes\n",
        "d_test.business_id = d_test.business_id.cat.codes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiJu5gtJ2SrT"
      },
      "outputs": [],
      "source": [
        "d_train = d_train.dropna()\n",
        "d_valid = d_valid.dropna()\n",
        "d_test = d_test.dropna()\n",
        "\n",
        "d_train.reset_index(drop=True, inplace=True)\n",
        "d_valid.reset_index(drop=True, inplace=True)\n",
        "d_test.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay3ZfUww2SrT"
      },
      "outputs": [],
      "source": [
        "d_train = d_train.astype({'user_id': int, 'business_id': int})\n",
        "d_valid = d_valid.astype({'user_id': int, 'business_id': int})\n",
        "d_test = d_test.astype({'user_id': int, 'business_id': int})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywuPffx-2SrU"
      },
      "outputs": [],
      "source": [
        "args.num_users = d_train.user_id.max() + 1\n",
        "args.num_items = d_train.business_id.max() + 1\n",
        "args.latent_dim = 64\n",
        "args.num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWacMu7k2SrU"
      },
      "outputs": [],
      "source": [
        "class GNNLayer(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GNNLayer, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats \n",
        "\n",
        "        self.W1 = nn.Linear(in_feats, out_feats)\n",
        "        self.W2 = nn.Linear(in_feats, out_feats)\n",
        "\n",
        "    def forward(self, L, SelfLoop, feats):\n",
        "        # (L+I)EW_1\n",
        "        sf_L = L + SelfLoop\n",
        "        L = L.cuda()\n",
        "        sf_L = sf_L.cuda()\n",
        "        sf_E = torch.sparse.mm(sf_L, feats)\n",
        "        left_part = self.W1(sf_E) # left part\n",
        "\n",
        "        # EL odot EW_2, odot indicates element-wise product \n",
        "        LE = torch.sparse.mm(L, feats)\n",
        "        E = torch.mul(LE, feats)\n",
        "        right_part = self.W2(E)\n",
        "\n",
        "        return left_part + right_part \n",
        "\n",
        "class NGCF(nn.Module):\n",
        "    def __init__(self, args, matrix):\n",
        "        super(NGCF, self).__init__()\n",
        "        self.num_users = args.num_users \n",
        "        self.num_items = args.num_items \n",
        "        self.latent_dim = args.latent_dim \n",
        "        self.device = args.device\n",
        "\n",
        "        self.user_emb = nn.Embedding(self.num_users, self.latent_dim)\n",
        "        self.item_emb = nn.Embedding(self.num_items, self.latent_dim)\n",
        "\n",
        "        self.num_layers = args.num_layers\n",
        "        self.L = self.LaplacianMatrix(matrix)\n",
        "        self.I = self.SelfLoop(self.num_users + self.num_items)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "        self.GNNLayers = nn.ModuleList()\n",
        "\n",
        "        for i in range(self.num_layers-1):\n",
        "            self.GNNLayers.append(GNNLayer(self.latent_dim, self.latent_dim))\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(self.latent_dim * self.num_layers * 2, 64), \n",
        "            nn.ReLU(), \n",
        "            nn.Linear(64, 32), \n",
        "            nn.ReLU(), \n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def SelfLoop(self, num):\n",
        "        i = torch.LongTensor([[k for k in range(0, num)], [j for j in range(0, num)]])\n",
        "        val = torch.FloatTensor([1]*num)\n",
        "        return torch.sparse.FloatTensor(i, val)\n",
        "\n",
        "    def LaplacianMatrix(self, ratings):\n",
        "        iids = ratings['business_id'] + self.num_users \n",
        "        matrix = sp.coo_matrix((ratings['stars'], (ratings['user_id'], ratings['business_id'])))\n",
        "        \n",
        "        upper_matrix = sp.coo_matrix((ratings['stars'], (ratings['user_id'], iids)))\n",
        "        lower_matrix = matrix.transpose()\n",
        "        lower_matrix.resize((self.num_items, self.num_users + self.num_items))\n",
        "\n",
        "        A = sp.vstack([upper_matrix, lower_matrix])\n",
        "        row_sum = (A > 0).sum(axis=1)\n",
        "        # row_sum = np.array(row_sum).flatten()\n",
        "        diag = list(np.array(row_sum.flatten())[0])\n",
        "        D = np.power(diag, -0.5)\n",
        "        D = sp.diags(D)\n",
        "        L = D * A * D\n",
        "        L = sp.coo_matrix(L)\n",
        "        row = L.row \n",
        "        col = L.col\n",
        "        idx = np.stack([row, col])\n",
        "        idx = torch.LongTensor(idx)\n",
        "        data = torch.FloatTensor(L.data)\n",
        "        SparseL = torch.sparse.FloatTensor(idx, data)\n",
        "        return SparseL \n",
        "\n",
        "    def FeatureMatrix(self):\n",
        "        uids = torch.LongTensor([i for i in range(self.num_users)]).to(self.device)\n",
        "        iids = torch.LongTensor([i for i in range(self.num_items)]).to(self.device)\n",
        "        user_emb = self.user_emb(uids)\n",
        "        item_emb = self.item_emb(iids)\n",
        "        features = torch.cat([user_emb, item_emb], dim=0)\n",
        "        return features\n",
        "\n",
        "    def forward(self, uids, iids):\n",
        "        iids = self.num_users + iids \n",
        "\n",
        "        features = self.FeatureMatrix()\n",
        "        final_emb = features.clone()\n",
        "\n",
        "        for gnn in self.GNNLayers:\n",
        "            features = gnn(self.L, self.I, features)\n",
        "            features = self.leakyrelu(features)\n",
        "            final_emb = torch.concat([final_emb, features],dim=-1)\n",
        "\n",
        "        user_emb = final_emb[uids]\n",
        "        item_emb = final_emb[iids]\n",
        "\n",
        "        inputs = torch.concat([user_emb, item_emb], dim=-1)\n",
        "        outs = self.fc_layer(inputs)\n",
        "        return outs.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWAAOhWf2SrV"
      },
      "outputs": [],
      "source": [
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        super(Dataset, self).__init__()\n",
        "        \n",
        "        self.uid = list(dataframe['user_id'])\n",
        "        self.iid = list(dataframe['business_id'])\n",
        "        self.ratings = list(dataframe['stars'])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.uid)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        uid = self.uid[idx]\n",
        "        iid = self.iid[idx]\n",
        "        rating = self.ratings[idx]\n",
        "        \n",
        "        return (uid, iid, rating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ei6g57T2SrV"
      },
      "outputs": [],
      "source": [
        "def get_loader(args, dataset, num_workers):\n",
        "    d_set = GraphDataset(dataset)\n",
        "    return DataLoader(d_set, batch_size=args.batch_size, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEAKyCaT2SrV",
        "outputId": "f18b3b9c-4be3-4272-826a-8fcf6b682a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_loader = get_loader(args, d_train, 4)\n",
        "valid_loader = get_loader(args, d_valid, 4)\n",
        "test_loader = get_loader(args, d_test, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p90stnoQ2SrV"
      },
      "outputs": [],
      "source": [
        "def graph_evaluate(args, model, test_loader, criterion):\n",
        "    output = []\n",
        "    test_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='evaluating...'):\n",
        "            batch = tuple(b.to(args.device) for b in batch)\n",
        "            inputs = {'uids':   batch[0], \n",
        "                      'iids':   batch[1]}\n",
        "            gold_y = batch[2].float()\n",
        "            \n",
        "            pred_y = model(**inputs)\n",
        "            output.append(pred_y)\n",
        "            \n",
        "            loss = criterion(pred_y, gold_y)\n",
        "            loss = torch.sqrt(loss)\n",
        "            test_loss += loss.item()\n",
        "    test_loss /= len(test_loader)\n",
        "    return test_loss, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtdUcB9B2SrW"
      },
      "outputs": [],
      "source": [
        "def graph_train(args, model, train_loader, valid_loader, optimizer, criterion):\n",
        "    best_loss = float('inf')\n",
        "    train_losses, valid_losses = [], []\n",
        "    for epoch in range(1, args.num_epochs + 1):\n",
        "        train_loss = 0.0\n",
        "\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc='training...'):\n",
        "            batch = tuple(b.to(args.device) for b in batch)\n",
        "            inputs = {'uids':   batch[0], \n",
        "                      'iids':   batch[1]}\n",
        "            \n",
        "            gold_y = batch[2].float()\n",
        "            \n",
        "\n",
        "            pred_y = model(**inputs)\n",
        "            \n",
        "            loss = criterion(pred_y, gold_y)\n",
        "            loss = torch.sqrt(loss)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        valid_loss , outputs = graph_evaluate(args, model, valid_loader, criterion)\n",
        "        valid_losses.append(valid_loss)\n",
        "        \n",
        "\n",
        "        print(f'Epoch: [{epoch}/{args.num_epochs}]')\n",
        "        print(f'Train Loss: {train_loss:.4f}\\tValid Loss: {valid_loss:.4f}')\n",
        "\n",
        "        if best_loss > valid_loss:\n",
        "            best_loss = valid_loss\n",
        "            if not os.path.exists(args.SAVE_PATH):\n",
        "                os.makedirs(args.SAVE_PATH)\n",
        "            torch.save(model.state_dict(), os.path.join(args.SAVE_PATH, f'{model._get_name()}_parameters.pt'))\n",
        "\n",
        "    return {\n",
        "        'train_loss': train_losses, \n",
        "        'valid_loss': valid_losses\n",
        "    }, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdoYFesy2SrW"
      },
      "outputs": [],
      "source": [
        "models = NGCF(args, d_train).to(args.device)\n",
        "\n",
        "optimizer = optim.Adam(models.parameters(), lr = 1e-3)\n",
        "criterion = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-uydHkQ2SrW",
        "outputId": "5573aa24-e53f-4d51-927f-b3ec173d9d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:04<00:00, 12.35it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/50]\n",
            "Train Loss: 1.1447\tValid Loss: 1.0922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.77it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 27.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2/50]\n",
            "Train Loss: 0.8451\tValid Loss: 1.0653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 25.52it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 35.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [3/50]\n",
            "Train Loss: 0.8139\tValid Loss: 1.0725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.62it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [4/50]\n",
            "Train Loss: 0.8091\tValid Loss: 1.0692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 32.08it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [5/50]\n",
            "Train Loss: 0.7950\tValid Loss: 1.1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.39it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [6/50]\n",
            "Train Loss: 0.7801\tValid Loss: 1.0620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 29.40it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 24.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [7/50]\n",
            "Train Loss: 0.7613\tValid Loss: 1.0611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 27.27it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [8/50]\n",
            "Train Loss: 0.7491\tValid Loss: 1.0926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 32.00it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 35.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [9/50]\n",
            "Train Loss: 0.7469\tValid Loss: 1.1331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.61it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [10/50]\n",
            "Train Loss: 0.7291\tValid Loss: 1.1388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 30.98it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 35.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [11/50]\n",
            "Train Loss: 0.7351\tValid Loss: 1.1446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 26.83it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 23.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [12/50]\n",
            "Train Loss: 0.7311\tValid Loss: 1.1252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 29.99it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [13/50]\n",
            "Train Loss: 0.7313\tValid Loss: 1.1013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.80it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [14/50]\n",
            "Train Loss: 0.7187\tValid Loss: 1.1461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.62it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 35.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [15/50]\n",
            "Train Loss: 0.6831\tValid Loss: 1.1349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.74it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [16/50]\n",
            "Train Loss: 0.7189\tValid Loss: 1.1184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 25.40it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 23.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [17/50]\n",
            "Train Loss: 0.7056\tValid Loss: 1.1753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.64it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 35.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [18/50]\n",
            "Train Loss: 0.6288\tValid Loss: 1.1889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.87it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [19/50]\n",
            "Train Loss: 0.5974\tValid Loss: 1.1835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.74it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 32.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [20/50]\n",
            "Train Loss: 0.5964\tValid Loss: 1.1662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.71it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [21/50]\n",
            "Train Loss: 0.6605\tValid Loss: 1.2439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 23.97it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 28.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [22/50]\n",
            "Train Loss: 0.6340\tValid Loss: 1.2203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.85it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [23/50]\n",
            "Train Loss: 0.6079\tValid Loss: 1.2273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 25.75it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:01<00:00, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [24/50]\n",
            "Train Loss: 0.6023\tValid Loss: 1.2247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.44it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [25/50]\n",
            "Train Loss: 0.6409\tValid Loss: 1.1450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 28.44it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 23.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [26/50]\n",
            "Train Loss: 0.6423\tValid Loss: 1.1680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 28.63it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [27/50]\n",
            "Train Loss: 0.6363\tValid Loss: 1.1722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.55it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [28/50]\n",
            "Train Loss: 0.6567\tValid Loss: 1.1794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.64it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [29/50]\n",
            "Train Loss: 0.6566\tValid Loss: 1.2296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.23it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [30/50]\n",
            "Train Loss: 0.6378\tValid Loss: 1.2298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 25.59it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 24.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [31/50]\n",
            "Train Loss: 0.6078\tValid Loss: 1.2210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.05it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [32/50]\n",
            "Train Loss: 0.6007\tValid Loss: 1.1778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.47it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [33/50]\n",
            "Train Loss: 0.6309\tValid Loss: 1.1680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.44it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [34/50]\n",
            "Train Loss: 0.5573\tValid Loss: 1.1712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 30.95it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [35/50]\n",
            "Train Loss: 0.5411\tValid Loss: 1.1753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 23.50it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 30.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [36/50]\n",
            "Train Loss: 0.5830\tValid Loss: 1.2604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.46it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [37/50]\n",
            "Train Loss: 0.6067\tValid Loss: 1.2566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.31it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [38/50]\n",
            "Train Loss: 0.5735\tValid Loss: 1.2543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.41it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [39/50]\n",
            "Train Loss: 0.5164\tValid Loss: 1.2527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.72it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 28.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [40/50]\n",
            "Train Loss: 0.4946\tValid Loss: 1.2665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 24.99it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [41/50]\n",
            "Train Loss: 0.5229\tValid Loss: 1.2286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.61it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [42/50]\n",
            "Train Loss: 0.5883\tValid Loss: 1.1932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.28it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [43/50]\n",
            "Train Loss: 0.5850\tValid Loss: 1.2231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.62it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [44/50]\n",
            "Train Loss: 0.5645\tValid Loss: 1.2465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 30.14it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 23.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [45/50]\n",
            "Train Loss: 0.5059\tValid Loss: 1.2426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 27.32it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 34.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [46/50]\n",
            "Train Loss: 0.4732\tValid Loss: 1.2298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.73it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [47/50]\n",
            "Train Loss: 0.4798\tValid Loss: 1.1924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.26it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [48/50]\n",
            "Train Loss: 0.5183\tValid Loss: 1.1831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:01<00:00, 31.73it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 33.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [49/50]\n",
            "Train Loss: 0.5492\tValid Loss: 1.2235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 59/59 [00:02<00:00, 27.01it/s]\n",
            "evaluating...: 100%|██████████| 20/20 [00:00<00:00, 23.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [50/50]\n",
            "Train Loss: 0.4633\tValid Loss: 1.2201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results = graph_train(args, models, train_loader, valid_loader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BN6gR6b2SrX",
        "outputId": "9d9e2cfe-a8e8-4686-c222-1fc06fe25718"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sm_37', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "torch.cuda.get_arch_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ona8ELUg2SrX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZi5jqAm2SrX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}