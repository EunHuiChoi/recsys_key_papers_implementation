{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyMoKBEGsD+TfxHzokSVZAN2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 학습 전"],"metadata":{"id":"o3nkC3HzrYcn"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5mLYJgHSorM","executionInfo":{"status":"ok","timestamp":1683991162975,"user_tz":-540,"elapsed":2284,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"db6a161c-b3c8-4ecd-b66f-a80d47f117c4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/000GithubRepos/000recsys_key_papers_implementation/model_comparison/kyeongchan/NGCF')"],"metadata":{"id":"FWfwnQKpS5Lp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install dgl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YdSP1UXedU6M","executionInfo":{"status":"ok","timestamp":1683991131531,"user_tz":-540,"elapsed":4273,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"534563e1-f802-4543-d8e2-da88921f4b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.24.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n"]}]},{"cell_type":"code","source":["from NGCF import NGCF\n","from load_data import Data"],"metadata":{"id":"IBKm_FdeTBAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This file is based on the NGCF author's implementation\n","# <https://github.com/xiangwang1223/neural_graph_collaborative_filtering/blob/master/NGCF/utility/parser.py>.\n","\n","import argparse\n","\n","\n","def parse_args():\n","    parser = argparse.ArgumentParser(description=\"Run NGCF.\")\n","    parser.add_argument(\"--weights_path\", nargs=\"?\", default=\"model/\", help=\"Store model path.\")\n","    parser.add_argument(\"--data_path\", nargs=\"?\", default=\"../Data/\", help=\"Input data path.\")\n","    parser.add_argument(\"--model_name\", type=str, default=\"NGCF.pkl\", help=\"Saved model name.\")\n","    parser.add_argument(\"--dataset\",nargs=\"?\",default=\"gowalla\",help=\"Choose a dataset from {gowalla, yelp2018, amazon-book}\",)\n","    parser.add_argument(\"--verbose\", type=int, default=1, help=\"Interval of evaluation.\")\n","    parser.add_argument(\"--epoch\", type=int, default=400, help=\"Number of epoch.\")\n","\n","    parser.add_argument(\"--embed_size\", type=int, default=64, help=\"Embedding size.\")\n","    parser.add_argument(\"--layer_size\",nargs=\"?\",default=\"[64,64,64]\",help=\"Output sizes of every layer\",)\n","    parser.add_argument(\"--batch_size\", type=int, default=1024, help=\"Batch size.\")\n","    parser.add_argument(\"--regs\", nargs=\"?\", default=\"[1e-5]\", help=\"Regularizations.\")\n","    parser.add_argument(\"--lr\", type=float, default=0.0001, help=\"Learning rate.\")\n","    parser.add_argument(\"--gpu\", type=int, default=0, help=\"0 for NAIS_prod, 1 for NAIS_concat\")\n","    parser.add_argument(\"--mess_dropout\",nargs=\"?\",default=\"[0.1,0.1,0.1]\",help=\"Keep probability w.r.t. message dropout (i.e., 1-dropout_ratio) for each deep layer. 1: no dropout.\",)\n","    parser.add_argument(\"--Ks\",nargs=\"?\",default=\"[20, 40]\",help=\"Output sizes of every layer\",)\n","\n","    parser.add_argument(\"--save_flag\",type=int,default=1,help=\"0: Disable model saver, 1: Activate model saver\",)\n","    parser.add_argument(\"--test_flag\",nargs=\"?\",default=\"part\",help=\"Specify the test type from {part, full}, indicating whether the reference is done in mini-batch\",)\n","\n","    parser.add_argument(\"--report\",type=int,default=0,help=\"0: Disable performance report w.r.t. sparsity levels, 1: Show performance report w.r.t. sparsity levels\",)\n","    return parser.parse_args([])\n","\n","args = parse_args()\n","Ks = eval(args.Ks)\n","vars(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZH9T7UA_WMuY","executionInfo":{"status":"ok","timestamp":1683991302085,"user_tz":-540,"elapsed":266,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"c2f18a33-c88b-4f0f-9024-534147fdbd4a"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'weights_path': 'model/',\n"," 'data_path': '../Data/',\n"," 'model_name': 'NGCF.pkl',\n"," 'dataset': 'gowalla',\n"," 'verbose': 1,\n"," 'epoch': 400,\n"," 'embed_size': 64,\n"," 'layer_size': '[64,64,64]',\n"," 'batch_size': 1024,\n"," 'regs': '[1e-5]',\n"," 'lr': 0.0001,\n"," 'gpu': 0,\n"," 'mess_dropout': '[0.1,0.1,0.1]',\n"," 'Ks': '[20, 40]',\n"," 'save_flag': 1,\n"," 'test_flag': 'part',\n"," 'report': 0}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["args.data_path = os.path.join('Data/')"],"metadata":{"id":"SV_xiQ2iWxr0","executionInfo":{"status":"ok","timestamp":1683991305785,"user_tz":-540,"elapsed":262,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["args.batch_size = 128"],"metadata":{"id":"q2sr6UzRkrDx","executionInfo":{"status":"ok","timestamp":1683991306823,"user_tz":-540,"elapsed":87,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["## batch_test import * 하기"],"metadata":{"id":"sEaj31sxYQW_"}},{"cell_type":"code","source":["import heapq\n","import multiprocessing\n","\n","# import utility.metrics as metrics\n","# from utility.load_data import *\n","# from utility.parser import parse_args\n","\n","cores = multiprocessing.cpu_count()\n","\n","data_generator = Data(path=args.data_path + args.dataset, batch_size=args.batch_size)\n","USR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\n","N_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\n","BATCH_SIZE = args.batch_size"],"metadata":{"id":"enpoTZXxV3gK","executionInfo":{"status":"ok","timestamp":1683991136709,"user_tz":-540,"elapsed":1846,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5ae57cd-01f0-4095-f434-6399f27e0003"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["n_users=29858, n_items=40981\n","n_interactions=1027370\n","n_train=810128, n_test=217242, sparsity=0.00084\n"]}]},{"cell_type":"code","source":["data_generator = Data(path=args.data_path + args.dataset, batch_size=args.batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpkD8IHGWd1b","executionInfo":{"status":"ok","timestamp":1683991137976,"user_tz":-540,"elapsed":1269,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"b1195ebf-eaaa-4109-a371-87fd6a821e05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["n_users=29858, n_items=40981\n","n_interactions=1027370\n","n_train=810128, n_test=217242, sparsity=0.00084\n"]}]},{"cell_type":"code","source":["USR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\n","N_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\n","BATCH_SIZE = args.batch_size"],"metadata":{"id":"783A1HcGXMfc","executionInfo":{"status":"ok","timestamp":1683991166983,"user_tz":-540,"elapsed":3,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## main"],"metadata":{"id":"_L4tVcMCYuqw"}},{"cell_type":"code","source":["args.weights_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zbZ_YoCgY2Kv","executionInfo":{"status":"ok","timestamp":1683991167770,"user_tz":-540,"elapsed":6,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"7f8c3c64-07f5-4511-b6da-5aa3072add74"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'model/'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["if not os.path.exists(args.weights_path):\n","    os.mkdir(args.weights_path)"],"metadata":{"id":"Nw2wXFHzYct3","executionInfo":{"status":"ok","timestamp":1683991170372,"user_tz":-540,"elapsed":259,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["args.mess_dropout = eval(args.mess_dropout)\n","args.mess_dropout\n","args.layer_size = eval(args.layer_size)\n","args.regs = eval(args.regs)\n","vars(args)"],"metadata":{"id":"NPDZICbRY07u","executionInfo":{"status":"ok","timestamp":1683991170766,"user_tz":-540,"elapsed":4,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6da4f4a-ad9d-4ffa-94f3-e345e80c2159"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'weights_path': 'model/',\n"," 'data_path': 'Data/',\n"," 'model_name': 'NGCF.pkl',\n"," 'dataset': 'gowalla',\n"," 'verbose': 1,\n"," 'epoch': 400,\n"," 'embed_size': 64,\n"," 'layer_size': [64, 64, 64],\n"," 'batch_size': 128,\n"," 'regs': [1e-05],\n"," 'lr': 0.0001,\n"," 'gpu': 0,\n"," 'mess_dropout': [0.1, 0.1, 0.1],\n"," 'Ks': '[20, 40]',\n"," 'save_flag': 1,\n"," 'test_flag': 'part',\n"," 'report': 0}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import os\n","from time import time\n","\n","import torch\n","import torch.optim as optim"],"metadata":{"id":"X28UtX20ZP2i","executionInfo":{"status":"ok","timestamp":1683991172118,"user_tz":-540,"elapsed":328,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["args.gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaSHVGD1auG0","executionInfo":{"status":"ok","timestamp":1683991175378,"user_tz":-540,"elapsed":2,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"0dc709d6-6c97-401b-f2c1-540d91884b07"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["if args.gpu >= 0 and torch.cuda.is_available():\n","    device = \"cuda:{}\".format(args.gpu)\n","else:\n","    device = \"cpu\""],"metadata":{"id":"GH-szjG5ZJFQ","executionInfo":{"status":"ok","timestamp":1683991180018,"user_tz":-540,"elapsed":283,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["g = data_generator.g\n","g = g.to(device)"],"metadata":{"id":"GJHSMgGQZrXB","executionInfo":{"status":"ok","timestamp":1683991180289,"user_tz":-540,"elapsed":3,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Step 2: Create model and training components=========================================================== #\n"],"metadata":{"id":"NZChJ7UBeX5r"}},{"cell_type":"code","source":["model = NGCF(g, args.embed_size, args.layer_size, args.mess_dropout, args.regs[0]).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=args.lr)"],"metadata":{"id":"yQOkU6kubTc-","executionInfo":{"status":"ok","timestamp":1683991183485,"user_tz":-540,"elapsed":291,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Exh0x7Xsy6tt","executionInfo":{"status":"ok","timestamp":1683991185981,"user_tz":-540,"elapsed":4,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"673b3e75-aaa2-4454-b6b5-963f63903a90"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NGCF(\n","  (layers): ModuleList(\n","    (0-2): 3 x NGCFLayer(\n","      (W1): Linear(in_features=64, out_features=64, bias=True)\n","      (W2): Linear(in_features=64, out_features=64, bias=True)\n","      (leaky_relu): LeakyReLU(negative_slope=0.2)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (feature_dict): ParameterDict(\n","      (item): Parameter containing: [torch.FloatTensor of size 40981x64]\n","      (user): Parameter containing: [torch.FloatTensor of size 29858x64]\n","  )\n",")"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[],"metadata":{"id":"j3_wTXl6skvZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: training epoches ============================================================================== #"],"metadata":{"id":"bmQQCQ1feeB1"}},{"cell_type":"code","source":["n_batch = data_generator.n_train // args.batch_size + 1\n","t0 = time()\n","cur_best_pre_0, stopping_step = 0, 0\n","loss_loger, pre_loger, rec_loger, ndcg_loger, hit_loger = [], [], [], [], []"],"metadata":{"id":"_Mx5d6mAeRjb","executionInfo":{"status":"ok","timestamp":1683991322265,"user_tz":-540,"elapsed":3,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# 학습"],"metadata":{"id":"mnHknnqdrk-r"}},{"cell_type":"markdown","source":["## 1epoch 학습"],"metadata":{"id":"klqfKfGkwG5p"}},{"cell_type":"code","source":["model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo5Ft6UujPap","executionInfo":{"status":"ok","timestamp":1683988755564,"user_tz":-540,"elapsed":271,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"a20299da-1e80-4129-d6a5-ed8f9f8ad309"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NGCF(\n","  (layers): ModuleList(\n","    (0-2): 3 x NGCFLayer(\n","      (W1): Linear(in_features=64, out_features=64, bias=True)\n","      (W2): Linear(in_features=64, out_features=64, bias=True)\n","      (leaky_relu): LeakyReLU(negative_slope=0.2)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (feature_dict): ParameterDict(\n","      (item): Parameter containing: [torch.FloatTensor of size 40981x64]\n","      (user): Parameter containing: [torch.FloatTensor of size 29858x64]\n","  )\n",")"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["perf_str = \"Epoch %d [%.1fs]: train==[%.5f=%.5f + %.5f]\" % (\n","    epoch,\n","    time() - t1,\n","    loss,\n","    mf_loss,\n","    emb_loss,\n",")\n","print(perf_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"nh1Zt7QuqoRx","executionInfo":{"status":"error","timestamp":1683991281722,"user_tz":-540,"elapsed":265,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"7fefddae-88a1-4265-9e93-00ea0a554574"},"execution_count":24,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-e01ea867a052>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m perf_str = \"Epoch %d [%.1fs]: train==[%.5f=%.5f + %.5f]\" % (\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmf_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"]}]},{"cell_type":"code","source":["type(ret)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kpvPm2wrQtR","executionInfo":{"status":"ok","timestamp":1683990895954,"user_tz":-540,"elapsed":408,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"52c70d2c-b767-493f-9362-87a8f47f4e10"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tuple"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"v8byFTWArnPI","executionInfo":{"status":"ok","timestamp":1683991403819,"user_tz":-540,"elapsed":252,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["from batch_test import test\n"],"metadata":{"id":"9jV7N4maq9_1","executionInfo":{"status":"ok","timestamp":1683991286113,"user_tz":-540,"elapsed":2,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xnouvVdusGyp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = {\n","    \"precision\": np.zeros(len(Ks)),\n","    \"recall\": np.zeros(len(Ks)),\n","    \"ndcg\": np.zeros(len(Ks)),\n","    \"hit_ratio\": np.zeros(len(Ks)),\n","    \"auc\": 0.0,\n","}\n","\n","pool = multiprocessing.Pool(cores)\n","\n","u_batch_size = 5000\n","i_batch_size = BATCH_SIZE\n","\n","test_users = users_to_test\n","n_test_users = len(test_users)\n","n_user_batchs = n_test_users // u_batch_size + 1\n","\n","count = 0"],"metadata":{"id":"49Ii6_sGqwHw","executionInfo":{"status":"ok","timestamp":1683991537945,"user_tz":-540,"elapsed":4670,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["batch_test_flag = False\n","for u_batch_id in range(n_user_batchs):\n","    start = u_batch_id * u_batch_size\n","    end = (u_batch_id + 1) * u_batch_size\n","\n","    user_batch = test_users[start:end]\n","\n","    if batch_test_flag:\n","        # batch-item test\n","        n_item_batchs = ITEM_NUM // i_batch_size + 1\n","        rate_batch = np.zeros(shape=(len(user_batch), ITEM_NUM))\n","\n","        i_count = 0\n","        for i_batch_id in range(n_item_batchs):\n","            i_start = i_batch_id * i_batch_size\n","            i_end = min((i_batch_id + 1) * i_batch_size, ITEM_NUM)\n","\n","            item_batch = range(i_start, i_end)\n","\n","            u_g_embeddings, pos_i_g_embeddings, _ = model(\n","                g, \"user\", \"item\", user_batch, item_batch, []\n","            )\n","            i_rate_batch = (\n","                model.rating(u_g_embeddings, pos_i_g_embeddings)\n","                .detach()\n","                .cpu()\n","            )\n","\n","            rate_batch[:, i_start:i_end] = i_rate_batch\n","            i_count += i_rate_batch.shape[1]\n","\n","        assert i_count == ITEM_NUM\n","\n","    else:\n","        # all-item test\n","        item_batch = range(ITEM_NUM)\n","        u_g_embeddings, pos_i_g_embeddings, _ = model(\n","            g, \"user\", \"item\", user_batch, item_batch, []\n","        )\n","        rate_batch = (\n","            model.rating(u_g_embeddings, pos_i_g_embeddings).detach().cpu()\n","        )\n","\n","    user_batch_rating_uid = zip(rate_batch.numpy(), user_batch)\n","    batch_result = pool.map(test_one_user, user_batch_rating_uid)\n","    count += len(batch_result)\n","\n","    for re in batch_result:\n","        result[\"precision\"] += re[\"precision\"] / n_test_users\n","        result[\"recall\"] += re[\"recall\"] / n_test_users\n","        result[\"ndcg\"] += re[\"ndcg\"] / n_test_users\n","        result[\"hit_ratio\"] += re[\"hit_ratio\"] / n_test_users\n","        result[\"auc\"] += re[\"auc\"] / n_test_users"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"Sxw32SAtta9z","executionInfo":{"status":"error","timestamp":1683991546728,"user_tz":-540,"elapsed":5058,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"d7acaa0d-52bb-452f-f04b-7bc9fb684285"},"execution_count":43,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)","\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-39-ed9bf17de817>\", line 23, in test_one_user\n    return get_performance(user_pos_test, r, auc, Ks)\n  File \"<ipython-input-40-a9e703f8468a>\", line 57, in get_performance\n    precision.append(metrics.precision_at_k(r, K))\nNameError: name 'metrics' is not defined\n\"\"\"","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-db1f321d3309>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0muser_batch_rating_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mbatch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_one_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_batch_rating_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         '''\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"]}]},{"cell_type":"code","source":["def test_one_user(x):\n","    # user u's ratings for user u\n","    rating = x[0]\n","    # uid\n","    u = x[1]\n","    # user u's items in the training set\n","    try:\n","        training_items = data_generator.train_items[u]\n","    except Exception:\n","        training_items = []\n","    # user u's items in the test set\n","    user_pos_test = data_generator.test_set[u]\n","\n","    all_items = set(range(ITEM_NUM))\n","\n","    test_items = list(all_items - set(training_items))\n","\n","    if args.test_flag == \"part\":\n","        r, auc = ranklist_by_heapq(user_pos_test, test_items, rating, Ks)\n","    else:\n","        r, auc = ranklist_by_sorted(user_pos_test, test_items, rating, Ks)\n","\n","    return get_performance(user_pos_test, r, auc, Ks)"],"metadata":{"id":"ynz6_5Ryta6M","executionInfo":{"status":"ok","timestamp":1683991496889,"user_tz":-540,"elapsed":3,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n","    item_score = {}\n","    for i in test_items:\n","        item_score[i] = rating[i]\n","\n","    K_max = max(Ks)\n","    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n","\n","    r = []\n","    for i in K_max_item_score:\n","        if i in user_pos_test:\n","            r.append(1)\n","        else:\n","            r.append(0)\n","    auc = 0.0\n","    return r, auc\n","\n","\n","def get_auc(item_score, user_pos_test):\n","    item_score = sorted(item_score.items(), key=lambda kv: kv[1])\n","    item_score.reverse()\n","    item_sort = [x[0] for x in item_score]\n","    posterior = [x[1] for x in item_score]\n","\n","    r = []\n","    for i in item_sort:\n","        if i in user_pos_test:\n","            r.append(1)\n","        else:\n","            r.append(0)\n","    auc = metrics.auc(ground_truth=r, prediction=posterior)\n","    return auc\n","\n","\n","def ranklist_by_sorted(user_pos_test, test_items, rating, Ks):\n","    item_score = {}\n","    for i in test_items:\n","        item_score[i] = rating[i]\n","\n","    K_max = max(Ks)\n","    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n","\n","    r = []\n","    for i in K_max_item_score:\n","        if i in user_pos_test:\n","            r.append(1)\n","        else:\n","            r.append(0)\n","    auc = get_auc(item_score, user_pos_test)\n","    return r, auc\n","\n","\n","def get_performance(user_pos_test, r, auc, Ks):\n","    precision, recall, ndcg, hit_ratio = [], [], [], []\n","\n","    for K in Ks:\n","        precision.append(metrics.precision_at_k(r, K))\n","        recall.append(metrics.recall_at_k(r, K, len(user_pos_test)))\n","        ndcg.append(metrics.ndcg_at_k(r, K))\n","        hit_ratio.append(metrics.hit_at_k(r, K))\n","\n","    return {\n","        \"recall\": np.array(recall),\n","        \"precision\": np.array(precision),\n","        \"ndcg\": np.array(ndcg),\n","        \"hit_ratio\": np.array(hit_ratio),\n","        \"auc\": auc,\n","    }"],"metadata":{"id":"cldCNRpSta0x","executionInfo":{"status":"ok","timestamp":1683991513932,"user_tz":-540,"elapsed":3,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JFdEjG7AtaAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(args.epoch):\n","    t1 = time()\n","    loss, mf_loss, emb_loss = 0.0, 0.0, 0.0\n","    for idx in range(n_batch):\n","        users, pos_items, neg_items = data_generator.sample()\n","        u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings = model(\n","            g, \"user\", \"item\", users, pos_items, neg_items\n","        )\n","\n","        batch_loss, batch_mf_loss, batch_emb_loss = model.create_bpr_loss(\n","            u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings\n","        )\n","        optimizer.zero_grad()\n","        batch_loss.backward()\n","        optimizer.step()\n","\n","        loss += batch_loss\n","        mf_loss += batch_mf_loss\n","        emb_loss += batch_emb_loss\n","\n","    if (epoch + 1) % 10 != 0:\n","        if args.verbose > 0 and epoch % args.verbose == 0:\n","            perf_str = \"Epoch %d [%.1fs]: train==[%.5f=%.5f + %.5f]\" % (\n","                epoch,\n","                time() - t1,\n","                loss,\n","                mf_loss,\n","                emb_loss,\n","            )\n","            print(perf_str)\n","        continue  # end the current epoch and move to the next epoch, let the following evaluation run every 10 epoches\n","\n","    # evaluate the model every 10 epoches\n","    t2 = time()\n","    users_to_test = list(data_generator.test_set.keys())\n","    ret = test(model, g, users_to_test)\n","    t3 = time()\n","\n","    loss_loger.append(loss)\n","    rec_loger.append(ret[\"recall\"])\n","    pre_loger.append(ret[\"precision\"])\n","    ndcg_loger.append(ret[\"ndcg\"])\n","    hit_loger.append(ret[\"hit_ratio\"])\n","\n","    if args.verbose > 0:\n","        perf_str = (\n","            \"Epoch %d [%.1fs + %.1fs]: train==[%.5f=%.5f + %.5f], recall=[%.5f, %.5f], \"\n","            \"precision=[%.5f, %.5f], hit=[%.5f, %.5f], ndcg=[%.5f, %.5f]\"\n","            % (\n","                epoch,\n","                t2 - t1,\n","                t3 - t2,\n","                loss,\n","                mf_loss,\n","                emb_loss,\n","                ret[\"recall\"][0],\n","                ret[\"recall\"][-1],\n","                ret[\"precision\"][0],\n","                ret[\"precision\"][-1],\n","                ret[\"hit_ratio\"][0],\n","                ret[\"hit_ratio\"][-1],\n","                ret[\"ndcg\"][0],\n","                ret[\"ndcg\"][-1],\n","            )\n","        )\n","        print(perf_str)\n","\n","    cur_best_pre_0, stopping_step, should_stop = early_stopping(\n","        ret[\"recall\"][0],\n","        cur_best_pre_0,\n","        stopping_step,\n","        expected_order=\"acc\",\n","        flag_step=5,\n","    )\n","\n","    # early stop\n","    if should_stop == True:\n","        break\n","\n","    if ret[\"recall\"][0] == cur_best_pre_0 and args.save_flag == 1:\n","        torch.save(model.state_dict(), args.weights_path + args.model_name)\n","        print(\n","            \"save the weights in path: \",\n","            args.weights_path + args.model_name,\n","        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"WMM4PANQeflU","outputId":"56c5f1c4-4d13-4085-b80f-34b7b694719c","executionInfo":{"status":"error","timestamp":1683991335353,"user_tz":-540,"elapsed":9428,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-d1d6a81b538c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         )\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), args.weights_path + args.model_name)"],"metadata":{"id":"K3hXjlM0epOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args.weights_path + args.model_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ot-etnQ_98NC","executionInfo":{"status":"ok","timestamp":1683962193889,"user_tz":-540,"elapsed":307,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"524323f0-9cf8-4b08-a852-762a6d9040bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'model/NGCF.pkl'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["torch.save(model.state_dict(), args.weights_path + args.model_name)"],"metadata":{"id":"0ce4Avod99_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.load_state_dict(torch.load(args.weights_path + args.model_name))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7U1n6v46sn24","executionInfo":{"status":"ok","timestamp":1683991259174,"user_tz":-540,"elapsed":4,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"846e4873-abcd-4ba9-d8e1-9cea74faf8c2"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NGCF(\n","  (layers): ModuleList(\n","    (0-2): 3 x NGCFLayer(\n","      (W1): Linear(in_features=64, out_features=64, bias=True)\n","      (W2): Linear(in_features=64, out_features=64, bias=True)\n","      (leaky_relu): LeakyReLU(negative_slope=0.2)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (feature_dict): ParameterDict(\n","      (item): Parameter containing: [torch.FloatTensor of size 40981x64]\n","      (user): Parameter containing: [torch.FloatTensor of size 29858x64]\n","  )\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import psutil\n","split_bar = '='*20\n","memory_info = psutil.virtual_memory()._asdict()\n","print(f\"{split_bar} Memory Usage {split_bar}\")\n","for k,v in memory_info.items():\n","  print(k, v)\n","print(f\"{split_bar} CPU Usage {split_bar}\")\n","print(f\"CPU percent: {psutil.cpu_percent()}%\")"],"metadata":{"id":"NlsAcFWiqefy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683991201326,"user_tz":-540,"elapsed":433,"user":{"displayName":"KYEONGCHAN LEE","userId":"03106579917275952793"}},"outputId":"8ef2d60b-9598-4ccb-8a17-40e5f89e7d85"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["==================== Memory Usage ====================\n","total 37836288000\n","available 35352576000\n","percent 6.6\n","used 1953996800\n","free 31852179456\n","active 972435456\n","inactive 4266545152\n","buffers 455294976\n","cached 3574816768\n","shared 1945600\n","slab 344133632\n","==================== CPU Usage ====================\n","CPU percent: 2.3%\n"]}]}]}